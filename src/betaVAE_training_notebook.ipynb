{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4109a940-0e39-4c87-a4a9-d1b14b3c0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam, SGD, RAdam\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "# from model import *\n",
    "from betaVAE import *\n",
    "from read_data import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87817e8c-3ca7-4e2c-829b-d2bf503a833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file: ../configs/betavae_tissues.json\n",
      "Checkpoint: ../checkpoitns\n",
      "Seed: 99\n",
      "Log: 0\n",
      "Parallel: None\n"
     ]
    }
   ],
   "source": [
    "# Simulating argparse functionality in a Jupyter Notebook\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = '../configs/betavae_tissues.json'  # Example: replace with your default config file\n",
    "        self.checkpoint = \"../checkpoitns\"       # Example: replace with your default checkpoint if any\n",
    "        self.seed = 99\n",
    "        self.log = 0\n",
    "        self.parallel = None\n",
    "\n",
    "# Instantiate the simulated args\n",
    "args = Args()\n",
    "\n",
    "# Access the arguments like this:\n",
    "print(f\"Config file: {args.config}\")\n",
    "print(f\"Checkpoint: {args.checkpoint}\")\n",
    "print(f\"Seed: {args.seed}\")\n",
    "print(f\"Log: {args.log}\")\n",
    "print(f\"Parallel: {args.parallel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ee3a1c5-ad53-417a-b475-61c20750f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.config) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25a0fa88-8664-45c3-b995-0dc86b0b0e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path_csv': ['../../RNA/data_for_beta_VAE/GTex_Lung_data_SSL_proteincoding.csv',\n",
       "  '../../RNA/data_for_beta_VAE/GTex_BrainCortex_proteincoding.csv',\n",
       "  '../../RNA/data_for_beta_VAE/GTex_Liver_proteincoding.csv',\n",
       "  '../../RNA/data_for_beta_VAE/GTex_Stomach_proteincoding.csv',\n",
       "  '../../RNA/data_for_beta_VAE/GTex_Pancreas_proteincoding.csv'],\n",
       " 'patch_data_path': '../../Histology/Lung_Patches256x256/',\n",
       " 'img_size': 256,\n",
       " 'max_patch_per_wsi': 100,\n",
       " 'rna_features': 19198,\n",
       " 'weights_decay': 0,\n",
       " 'lr': 5e-05,\n",
       " 'num_epochs': 500,\n",
       " 'n_workers': 4,\n",
       " 'device': 0,\n",
       " 'flag': 'betavae_proteincoding_tissues',\n",
       " 'save_dir': '../checkpoints/betavae_training_tissues/',\n",
       " 'summary_path': '../summaries_betavae_tissues/',\n",
       " 'log_interval': 20,\n",
       " 'bag_size': 40,\n",
       " 'batch_size': 128,\n",
       " 'beta': 0.0005,\n",
       " 'quick': 0,\n",
       " 'optimizer': 'Adam'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55b7a890-fa8f-4242-bcf6-08405f8f9d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Config for this experiment \n",
      "\n",
      "{'path_csv': ['../../RNA/data_for_beta_VAE/GTex_Lung_data_SSL_proteincoding.csv', '../../RNA/data_for_beta_VAE/GTex_BrainCortex_proteincoding.csv', '../../RNA/data_for_beta_VAE/GTex_Liver_proteincoding.csv', '../../RNA/data_for_beta_VAE/GTex_Stomach_proteincoding.csv', '../../RNA/data_for_beta_VAE/GTex_Pancreas_proteincoding.csv'], 'patch_data_path': '../../Histology/Lung_Patches256x256/', 'img_size': 256, 'max_patch_per_wsi': 100, 'rna_features': 19198, 'weights_decay': 0, 'lr': 5e-05, 'num_epochs': 500, 'n_workers': 4, 'device': 0, 'flag': 'betavae_proteincoding_tissues', 'save_dir': '../checkpoints/betavae_training_tissues/', 'summary_path': '../summaries_betavae_tissues/', 'log_interval': 20, 'bag_size': 40, 'batch_size': 128, 'beta': 0.0005, 'quick': 0, 'optimizer': 'Adam'}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(10*'-')\n",
    "print('Config for this experiment \\n')\n",
    "print(config)\n",
    "print(10*'-')\n",
    "\n",
    "if 'flag' in config:\n",
    "    args.flag = config['flag']\n",
    "else:\n",
    "    args.flag = 'train_{date:%Y-%m-%d %H:%M:%S}'.format(date=datetime.datetime.now())\n",
    "\n",
    "if not os.path.exists(config['save_dir']):\n",
    "    os.mkdir(config['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65e3b8ea-6e42-486e-af3d-d46933c8af0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "path_csv = config['path_csv']\n",
    "rna_features = config['rna_features']\n",
    "batch_size = config.get('batch_size', 64)\n",
    "encoder_checkpoint = config.get('encoder_checkpoint', None)\n",
    "beta = config.get('beta', 2)\n",
    "quick = config.get('quick', 0)\n",
    "opt = config.get('optimizer', 'Adam')\n",
    "\n",
    "print('Loading dataset...')\n",
    "\n",
    "datasets = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4ade2c4e-6f2f-4f14-bd53-829ecb835eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dfs(train_df, val_df, test_df, labels=False, norm_type='standard'):\n",
    "    def _get_log(x):\n",
    "        # trick to take into account zeros\n",
    "        x = np.log(x.replace(0, np.nan))\n",
    "        return x.replace(np.nan, 0)\n",
    "    # get list of columns to scale\n",
    "    rna_columns = [x for x in train_df.columns if 'rna_' in x]\n",
    "    \n",
    "    \n",
    "    # log transform\n",
    "    train_df[rna_columns] = train_df[rna_columns].apply(_get_log)\n",
    "    val_df[rna_columns] = val_df[rna_columns].apply(_get_log)\n",
    "    test_df[rna_columns] = test_df[rna_columns].apply(_get_log)\n",
    "    \n",
    "    \n",
    "    train_df = train_df[rna_columns+['wsi_file_name']]\n",
    "    val_df = val_df[rna_columns+['wsi_file_name']]\n",
    "    test_df = test_df[rna_columns+['wsi_file_name']]\n",
    "    \n",
    "    rna_values = train_df[rna_columns].values\n",
    "\n",
    "    if norm_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif norm_type == 'minmax':\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    rna_values = scaler.fit_transform(rna_values)\n",
    "\n",
    "    train_df[rna_columns] = rna_values\n",
    "    test_df[rna_columns] = scaler.transform(test_df[rna_columns].values)\n",
    "    val_df[rna_columns] = scaler.transform(val_df[rna_columns].values)\n",
    "\n",
    "    return train_df, val_df, test_df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c51e6115-dae6-4cf1-90c6-4e697291c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../RNA/data_for_beta_VAE/GTex_Lung_data_SSL_proteincoding.csv\n",
      "../../RNA/data_for_beta_VAE/GTex_BrainCortex_proteincoding.csv\n",
      "../../RNA/data_for_beta_VAE/GTex_Liver_proteincoding.csv\n",
      "../../RNA/data_for_beta_VAE/GTex_Stomach_proteincoding.csv\n",
      "../../RNA/data_for_beta_VAE/GTex_Pancreas_proteincoding.csv\n"
     ]
    }
   ],
   "source": [
    "for id, dataset in enumerate(path_csv):\n",
    "    print(dataset)\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    df_transposed = df.set_index('gene_id').transpose().reset_index()\n",
    "    df_transposed.rename(columns={'index': 'wsi_file_name'}, inplace=True)\n",
    "\n",
    "    train_df, test_df = train_test_split(df_transposed, test_size=0.2)\n",
    "\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "    train_df, val_df, test_df, scaler = normalize_dfs(train_df, val_df, test_df, norm_type='minmax')\n",
    "\n",
    "    datasets['train'].append(train_df)\n",
    "    datasets['test'].append(test_df)\n",
    "    datasets['val'].append(val_df)\n",
    "    \n",
    "    test_labels = test_labels + ([id] * test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "988bc980-b42b-444c-be3f-63fba5b4215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (62514, 20899)\n",
      "Val shape (15634, 20899)\n",
      "Test shape (19541, 20899)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dennis00/anaconda3/envs/scRNA-GAN-TF/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/dennis00/anaconda3/envs/scRNA-GAN-TF/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_289176/2577892708.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[rna_columns] = rna_values\n",
      "/tmp/ipykernel_289176/2577892708.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[rna_columns] = scaler.transform(test_df[rna_columns].values)\n",
      "/tmp/ipykernel_289176/2577892708.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df[rna_columns] = scaler.transform(val_df[rna_columns].values)\n",
      "62514it [14:57, 69.68it/s]\n",
      "15634it [03:36, 72.32it/s]\n",
      "19541it [04:33, 71.33it/s]\n"
     ]
    }
   ],
   "source": [
    "if(len(datasets['train']) >=2):\n",
    "    train_df = pd.concat([datasets['train'][0], datasets['train'][1]])\n",
    "    val_df = pd.concat([datasets['val'][0], datasets['val'][1]])\n",
    "    test_df = pd.concat([datasets['test'][0], datasets['test'][1]])\n",
    "    for i in range(2, len(datasets['train'])):\n",
    "        train_df = pd.concat([train_df, datasets['train'][i]])\n",
    "        val_df = pd.concat([val_df, datasets['val'][i]])\n",
    "        test_df = pd.concat([test_df, datasets['test'][i]])\n",
    "else:\n",
    "    train_df = datasets['train'][0]\n",
    "    val_df = datasets['val'][0]\n",
    "    test_df = datasets['test'][0]\n",
    "\n",
    "print('Train shape {}'.format(train_df.shape))\n",
    "print('Val shape {}'.format(val_df.shape))\n",
    "print('Test shape {}'.format(test_df.shape))\n",
    "train_df, val_df, test_df, scaler = normalize_dfs(train_df, val_df, test_df, norm_type='standard')\n",
    "\n",
    "train_dataset = RNADataset([train_df], quick=quick)\n",
    "val_dataset = RNADataset([val_df])\n",
    "test_dataset = RNADataset([test_df])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size, \n",
    "               num_workers=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=batch_size, \n",
    "               num_workers=4, \n",
    "               shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=1, \n",
    "               num_workers=4, \n",
    "               shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
